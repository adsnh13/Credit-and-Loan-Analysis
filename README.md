# ONLINE BANKING ANALYSIS

This is a project in which the development of an end-to-end big data pipeline based on Apache Spark has taken place. The datasets were from the Kaggle consisting of loan, customer credit card and transaction data, which were cleaned to be accurate and ready to be analysed.

The workflow employed the use of Spark to manage and work on large data volumes effectively. Data was absorbed through the process of getting it on Kaggle. The advanced analytics were carried out in PySpark on the Jupyter Notebook by applying several use cases.

This pipeline shows that even with the modern big data tools, Spark, combined with them, can be used to quickly process, format and analyze large data sets.
                            
 ## TECHNOLOGIES USED:
- Apache Spark (Spark SQL, Spark Core)  
- PySpark (Jupyter Notebook)  
- Pandas  
- Matplotlib  
- Seaborn  
                 
 ## SUMMARY:
- Utilized historical datasets sourced from **Kaggle**.  
- Collected and analyzed **three datasets**: online transactions, loans, and customer credit cards.  
- Implemented **Spark Session** to load data into Spark DataFrames.  
- Executed **Spark SQL queries** in standalone cluster mode for efficient computation.  
- Applied **data cleaning, structuring, and visualization** techniques to derive insights.  
