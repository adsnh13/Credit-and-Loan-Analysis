# ONLINE BANKING ANALYSIS

TThis is a project in which the development of an end-to-end big data pipeline based on Apache Spark has taken place. The datasets were from the Kaggle consisting of loan, customer credit card and transaction data, which were cleaned to be accurate and ready to be analysed.

The workflow employed the use of Spark, HDFS, Hive and Sqoop to manage and work on large data volumes effectively. Data was absorbed through the process of getting it on Kaggle, putting it in a cloud storage system and then importing it into Hive via MySQL with Sqoop. Data that have been processed were structured in Hive, and the advanced analytics were carried out in PySpark on the Jupyter Notebook by applying several use cases.

This pipeline shows that even with the modern big data tools, Spark, combined with them, can be used to quickly process, format and analyze large data sets.
                            
 ## TECHNOLOGIES USED:
- Apache Spark (Spark SQL, Spark Core)  
- PySpark (Jupyter Notebook)  
- Pandas  
- Matplotlib  
- Seaborn  
                 
 ## SUMMARY:
 Utilized the historical data from kaggle.com.
 Collected 3 datasets of online transactions, loan and customer credit card.
 Implemented Spark Session to load the data into Data Frames.
 Used standalone cluster mode in spark environment to run on Spark SQL queries.
